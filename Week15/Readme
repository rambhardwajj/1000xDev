<!-- DevOps Highlevel Whys -->
	1 how can you make docker container 
	2 how is it usefull for starting project locally 
	3 how can you deploy your project using docker 

<!-- How to setup opensource project locally conventially  -->
	1. git clone 
	2. install dependency 

<!-- How to setup opensource project locally using docker  -->
	1. clone that project locally 
	2. start a command given in the project 
		this command will start a container ( mini computer OR self contained VM ) on your machine 
	3. this will install all you dependencies 
	4. and when you are done you cna stop the container nd then all the resources are free

Company's Developer will make an image and that image can be run on any machine teh same way everywhere. 
The image actually running is called the container 

<!-- What is an image? -->
Image is a very big file ( 200 mb etc ).
Take it like it is a snapshot of the dependecies of a project all together 

<!-- Difference between an Imge and container -->
1.	Image is a big file that has all the dependencies for the project 
	Container is an image under execution 
2.	Image is made once 
	Containers are created multiple times
3. 	Image pushed to a docker hub 
	Containers run on different Ec2/Gcp instances etc 
__________________________________________________________________________________________________________________________________________________________________________________________

<!-- DOCKER -->
The Most Popular Container 

<!-- Docker has 3 parts  -->
	Docker engine -> something that run on your machine , thing that create images on your 
		machine and run it 
	Docker CLI -> way to interact to Docker using command line 
	Docker Hub -> place where images are deployed 

<!-- Workflow  -->
	The Maintainers will create an Image ( a docker file ) and then 
	Push it to DockerHub and then 
	The differenct ec2 instances can pull the image from the docker hub and run it 
	 using their docker engines. 
	

<!-- Few Points to note  -->
1.	Usually the databases are deployed seperately and backend , frontend applications are running on ec2 instances
2.	Usually you dont start the database using docker , because docker keeps going down ( On and Off ) and u dont want your database going down and data lost 
3.	Only you upload your frontend and backend code on ec2 instances

<!-- DockerFile -->
File that describe your image 
	steps to write a docker image :-
		1. first line of the docker file is your base image 
			eg Nodejs base image ( it represent popular image of machine like ubuntu or ubuntu + nodejs [node js ])
		2. All software to install 
		3. Copy over the file you want to be present in the container ( your frontend code or your backend code )
		4. build the project ( npm i , npm run build , )
		5. expose write set of ports 
		6. start the process
______________________________________________________________________________________________

<!-- When you have to containerise your application These Are The Steps You Have To Follow -->
	1. Add a docker file week-15/part1-simple-node-app/Dockerfile
	2. Create the image and start the container
		docker build -t <Name_of_the_image> . 
		docker images (for confirmation)
		docker run -p 3000:3000 <Name_of_the_image>
		 
<!-- Docker Layers -->
	Suppose you have to make a container
	you have a docker file which has 4 commands 
	the docker engine will start from the top and it 
	will start to make these LAYERS 
	the reason why these layers are created is because a lot of times these layers can be cashed .
	Building docker is verytime consuming step 
	the bottom layer images changes very rarely , so it is very usefull to cache these to save time
<!-- Basically for saving build operations these layers are made which can be cashed to save the operations -->


<!-- Grabbing images from dockerhub -->
	docker run -d -p 27017:27017 mongo 
		this will start mongodb locally
		here -p is port mapping 
		here -d id detached mode ( run it in backgraound)
		by changing the ports number you can start different mongodb instances locally 



<!-- How to push an image to dockerHub -->
	Step 1 -> login to docker hub
	Step 2 -> On windows search for docker desktop and double click and start the docker engine 
	Step 3 -> Open dockerHub and login 
	Step 4 -> make a new repository, give it a name 
	Step 5 -> now come back to your editor and   cd to the docker project where the docker file exist 
	Step 6 -> open terminal  ( login to docker )
				docker login 
	Step 7 -> build docker image 
				docker build -t rambhardwaj1010/test11 .     ( here rambhardwaj1010/test11 is the repo name of docker hub  ) 
	Step 8 -> push image
				docker push rambhardwaj1010/test11
	Step 9 -> run the image locally 
				docker run -p 3002:3000 rambhardwaj1010/test11
	Step 10-> end the process
				docker ps 
				docker kill <IdOfContainer>

<!-- People having your image can go to the image and see the source code and hence you should upload binary files or for js some hashed file on docker  -->
<!-- Frontend are not deployed useing docker , only backend are deployed useing docker in real world -->
<!-- We build the docker image locally and not on a ec2 instance as this will take a lot of computation power and hence kinda avoided -->
<!-- In real world there are different backend apis , each backend apis have their seperate dockerfile and these docker file when getting upload in the workflows are moved to the root folder because the dockerfile are supposed to be in the root folder  -->

<!-- Docker Volume  -->
	It is a place that you create in your docker engine and say that whatever data you put there you keep it  the volume will keep it alive even if the docker turns off (until we actually kill the volume ) 
<!-- thing you should know is when an image is build the first place where  data is stored is /data/db folder -->

<!-- How to create a volume in mongo db? -->
	docker volume create <volumename>
	docker run -v <volumename>:/data/db -p 27017:27017 mongo 
			whenever mongo container starts the place where it puts all the data is the /data/db of the container  

<!-- Docker Network -->
	To communicate between different containers. Every container is a seperate machine so differenct containers cant cant unless they are connected to a network

<!-- How to create a network? -->
	docker network create <network_Name>
	docker run --name <Container_Name> --network <network_Name> -d <nameOfImage> 
	docker run --name <Container2_Name> --network <network_Name> it busybox sh <nameOfImage>

<!-- BusyBox -->
	this is like sshing into container but this also has few linux command to operate into container machine 

<!-- Docker Compose file -->
see image 
	When u use a docker compose file , u want the user to run a single command that starts mongo , starts app, etc etc 